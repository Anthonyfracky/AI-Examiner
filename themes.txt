What is Natural Language Processing (NLP)?
What are the main tasks that NLP solves?
What is the difference between lemmatization and stemming?
What is tokenization? What is it used for?
What are stop words? Give examples.
What is the goal of part-of-speech tagging (POS tagging)?
What is an n-gram? How is it used in NLP?
How does the Bag of Words (BoW) model work?
What is TF-IDF and what is it used for?
What is the essence of Word2Vec? What are the main methods for training this model?
What is a Transformer neural network?
How does the self-attention mechanism work in NLP models?
What is a Sequence-to-Sequence model? Where is it applied?
How do recurrent neural networks (RNNs) work in the context of NLP?
What is BERT, and how does it differ from traditional NLP models?
How does GPT (Generative Pre-trained Transformer) generate text?
What is fine-tuning in the context of transformers?
How are embeddings used in modern NLP models?
How does a machine translation system work?
What is sentiment analysis? How is it performed?
What approaches are used to detect fake news?
How are chatbots implemented using NLP?
What is named entity recognition (NER)?
How does text classification work?
What libraries are most commonly used for NLP? (e.g., NLTK, spaCy, Hugging Face)
What are the advantages and disadvantages of the Hugging Face library?
How does the Pipeline work in the Transformers library?
What are the main challenges facing NLP in a multilingual environment?
How can the problem of data imbalance be solved in NLP tasks?
What is zero-shot learning and how is it used in NLP?