Що таке Natural Language Processing (NLP)?
Які основні завдання вирішує NLP?
У чому різниця між лемматизацією та стемінгом?
Що таке токенізація? Для чого вона потрібна?
Що таке стоп-слова? Наведіть приклади.
Яка мета частиномовного аналізу (POS tagging)?
Що таке n-грам? Як вона використовується у NLP?
Як працює метод Bag of Words (BoW)?
Що таке TF-IDF і для чого його застосовують?
У чому суть Word2Vec? Які основні методи навчання цієї моделі?
Що таке нейронна мережа Transformer?
Як працює механізм self-attention у моделях NLP?
Що таке Sequence-to-Sequence модель? Де вона застосовується?
Як працюють рекурентні нейронні мережі (RNN) у контексті NLP?
Що таке BERT, і чим він відрізняється від традиційних NLP-моделей?
Як GPT (Generative Pre-trained Transformer) генерує текст?
Що таке fine-tuning у контексті трансформерів?
Як використовується embeddings у сучасних NLP-моделях?
Як працює система автоматичного перекладу тексту?
Що таке аналіз сентименту? Як його виконують?
Які підходи використовуються для виявлення фейкових новин?
Як реалізуються чат-боти з використанням NLP?
Що таке розпізнавання сутностей (NER)?
Як працює класифікація текстів?
Які бібліотеки найчастіше використовуються для NLP? (наприклад, NLTK, spaCy, Hugging Face)
У чому переваги та недоліки бібліотеки Hugging Face?
Як працює Pipeline у бібліотеці Transformers?
Які основні виклики стоять перед NLP у багатомовному середовищі?
Як можна розв’язувати проблему дисбалансу даних у задачах NLP?
Що таке zero-shot learning і як воно використовується у NLP?